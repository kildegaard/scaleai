{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codigo 1\n",
    "\n",
    "Here's a sample code for the views.py file that includes logging configuration, optional Sentry integration for error tracking, and the definition of a Celery task to process the dataset asynchronously.\n",
    "\n",
    "```python\n",
    "from rest_framework import status\n",
    "from rest_framework.response import Response\n",
    "from rest_framework.views import APIView\n",
    "from django.conf import settings\n",
    "from celery import shared_task\n",
    "import logging\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Optional: Configure Sentry for error tracking\n",
    "if settings.SENTRY_DSN:\n",
    "    import sentry_sdk\n",
    "    sentry_sdk.init(dsn=settings.SENTRY_DSN)\n",
    "\n",
    "# Define a Celery task to process the dataset asynchronously\n",
    "@shared_task(name='process_dataset')\n",
    "def process_dataset(dataset):\n",
    "    # Implement the logic to process the dataset here\n",
    "    # This task will run in the background using Celery\n",
    "    logger.info('Processing dataset...')\n",
    "    # Simulate processing time\n",
    "    import time\n",
    "    time.sleep(5)\n",
    "    logger.info('Dataset processing completed.')\n",
    "\n",
    "class DatasetUploadView(APIView):\n",
    "    def post(self, request):\n",
    "        try:\n",
    "            dataset = request.FILES['dataset']\n",
    "            # Trigger the Celery task to process the dataset asynchronously\n",
    "            task_id = process_dataset.apply_async(args=(dataset,), countdown=10)\n",
    "            return Response({'task_id': task_id.id}, status=status.HTTP_202_ACCEPTED)\n",
    "        except Exception as e:\n",
    "            logger.error(f'Error uploading dataset: {str(e)}')\n",
    "            if settings.SENTRY_DSN:\n",
    "                sentry_sdk.capture_exception(e)\n",
    "            return Response({'error': 'Failed to upload dataset'}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "*   We set up basic logging with `logging.basicConfig` and create a logger instance.\n",
    "*   If a Sentry DSN is configured in Django settings, we initialize Sentry for error tracking.\n",
    "*   The `process_dataset` function is decorated with `@shared_task` to define it as a Celery task. It simulates dataset processing by sleeping for 5 seconds and logs information messages before and after processing.\n",
    "*   In the `DatasetUploadView`, we handle the dataset upload through the `post` method. It triggers the `process_dataset` Celery task to run asynchronously with a 10-second delay (using `countdown=10`) and returns a response with the task ID.\n",
    "*   If any exceptions occur during dataset upload or task triggering, they are caught, logged, and optionally reported to Sentry. An appropriate error response is returned in such cases.\n",
    "\n",
    "Remember to install required packages (`celery` and `sentry-sdk`) and configure Celery and Sentry correctly in your Django project settings to use this code effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codigo 2\n",
    "\n",
    "Here's a sample code for the `views.py` file that incorporates logging configuration, optional Sentry integration for error tracking, and a Celery task to process the dataset asynchronously:\n",
    "\n",
    "```python\n",
    "import logging\n",
    "from rest_framework.response import Response\n",
    "from rest_framework.views import APIView\n",
    "from celery import shared_task\n",
    "from django.core.files.storage import default_storage\n",
    "from django.core.files.base import ContentFile\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Optional Sentry integration for error tracking\n",
    "try:\n",
    "    import sentry_sdk\n",
    "    from sentry_sdk.integrations.django import DjangoIntegration\n",
    "    sentry_sdk.init(\"YOUR_SENTRY_DSN\", integrations=[DjangoIntegration()])\n",
    "except ImportError:\n",
    "    logger.info(\"Sentry integration is not available.\")\n",
    "\n",
    "# Define the Celery task to process the dataset asynchronously\n",
    "@shared_task(name=\"process_dataset\")\n",
    "def process_dataset(file_path):\n",
    "    try:\n",
    "        # Implement your dataset processing logic here\n",
    "        with default_storage.open(file_path, 'r') as file:\n",
    "            # Process the file\n",
    "            logger.info(f\"Processing dataset: {file_path}\")\n",
    "            # Replace this with your actual processing logic\n",
    "            processed_data = file.read()\n",
    "            return processed_data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing dataset: {str(e)}\")\n",
    "        # Optionally, track the error in Sentry\n",
    "        try:\n",
    "            sentry_sdk.capture_exception(e)\n",
    "        except NameError:\n",
    "            pass\n",
    "\n",
    "class DatasetUploadView(APIView):\n",
    "    def post(self, request):\n",
    "        try:\n",
    "            # Handle the uploaded dataset\n",
    "            file = request.FILES['file']\n",
    "            file_path = default_storage.save(file.name, ContentFile(file.read()))\n",
    "            # Trigger the Celery task to process the dataset asynchronously\n",
    "            task = process_dataset.apply_async(args=(file_path,))\n",
    "            return Response({\"task_id\": task.id}, status=202)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error uploading dataset: {str(e)}\")\n",
    "            # Optionally, track the error in Sentry\n",
    "            try:\n",
    "                sentry_sdk.capture_exception(e)\n",
    "            except NameError:\n",
    "                pass\n",
    "            return Response({\"error\": str(e)}, status=400)\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "*   Logging is configured using the `logging` module.\n",
    "*   Optional Sentry integration is included for error tracking. You should replace `\"YOUR_SENTRY_DSN\"` with your actual Sentry DSN.\n",
    "*   A Celery task named `process_dataset` is defined to process the dataset asynchronously. This task takes a file path as an argument, reads the file, and processes it. You should replace the comment with your actual dataset processing logic.\n",
    "*   The `DatasetUploadView` handles dataset uploads via the API endpoint. It saves the uploaded file, triggers the `process_dataset` Celery task, and returns a response with the task ID.\n",
    "\n",
    "Make sure to install the required packages, including Celery and Sentry SDK, and configure Celery and Sentry according to their respective documentation. Additionally, adapt the code to fit your specific requirements and handle potential errors based on your application's needs."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
