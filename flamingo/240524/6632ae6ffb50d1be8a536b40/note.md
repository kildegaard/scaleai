# prompt 1

I am building a backend system in Python to handle the user's name. Create a class to join the first name and last name into a full name. This functionality should be implemented as a method within the class. There should be a constructor in the class so that when an instance of the class is created, the user's name is initialized to John Doe.


El flaco eligió mal la respuesta pq SON IGUALES y le mandó que había deviation en Reasoning quality

# justif 1 original

Response 1 is better than response 2.

Reasoning Quality: In response 1, in lines 1-3 of the code, response 1 used Username and response 2 used Fullname as class name. Username is more efficient in this case because this is the class that handles the user's name. Fullname is not a good option.
And response 1 provides a step-by-step breakdown of what the code does. The code is compiled and run without any errors successfully in the Sphere engine.

# Justif 1 modificada

Response 1 and response 2 delivered the same code, regardless of the exact words. Even the non-code section is almost the same. For this, we can conclude that there is no deviation whatsoever.
The reason for the rating is totally trivial: it could have been 5 equally because both codes are the exact same.
Despite the simple code, both were tested in Visual Studio Code.


# Prompt 2

Great. Thank you. Now please add the function to uppercase the first letters of the user's name. So it will uppercase the first letter of the first name and last name if it receives the full name as a parameter.

Le bajé de 7 a 5

# Justif 2 original

Response 2 is better than response 1.

Reasoning Quality: In the code of response 1, from code lines 9-12, it used uppercase_name and in response 2, it used format_name. BTW, format_name is the more efficient name for the function to uppercase the first character of first name and last name. In response 2, it used core more simply than response 1. It tried to write the function in one line but response 1 takes 3 lines.

# Justif 2 modif

Both responses answer all the queries in the second prompt. They added a function that capitalizes the initial letters of first and last names. They are just about the same and, for that, there is no deviation at all. The ranking is 5 but it could have been 4 just the same.
Both codes were tested as before, in VSCode.


# prompt 3

Great. Finally, provide a function to save the length of the user's name. And save it to a private variable in the class. This can help predict the user's nationality.

# justif 3 orig

Response 2 is slightly better than response 1.

Functionality & Performance: Response 2 provides more simple code than response 1. In response 2, from lines 13-19, it provides 2 functions. get_name_length and save_name_length. It makes the function in one line which makes it more readable and simple. In response 1, it provides many lines for the function. In other things, they provide good explanations and output the result correctly.

# Justif 3 modif

Response 2 is slightly better than response 1, but no deviation was found in this case.
Response 2 provides a more simple code than response 1. In response 2, from lines 13-19, it provides 2 functions. get_name_length and save_name_length. It makes the function in one line which makes it more readable and simple. In response 1, it provides many lines for the function. In other things, they provide good explanations and output the result correctly.
Codes tested in VSCode.


# Feedback

Hello, dear Tasker. Thanks a lot for your commitment to the actual project.
I reviewed your work and wanted to share my thoughts.

According to actual guidelines, your prompts have several issues to deal with and your justifications lack some compulsory elements for them to be excellent ones.

Your prompts need to have a certain structure considering the following:
- Context: giving some environmental information will buff your prompt as the model has information to be more specific and clever.
- Clear objectives: well-explained goals for the code or problem to achieve.
- Use cases: propose uses for the code to be useful within specific situations
- Constraints: adding extra spice to the model is a good way to increase its quality. Think about specific limitations to take into account or restrictions that would make the problem non-trivial.
- Uniqueness: as stated previously, your problem must provide some fresh ideas to the prompt pool. It's expected for you to write problems that are not so easily found on the internet.
- Complexity: Once again, as stated before, the problem must not be trivial. It would be best if you aimed for issues that require some effort for the model, that provide a clear yet not easy way for solving them.

In your case, the prompts were good but lacked a bit of context and constraints. They were a bit too simple but passed just by a bit. For next ones, please consider increasing the complexity.

Another topic to engage in is justifications: in the documentation, there's plenty of information to learn some workflow to tackle this. I'll add them at the end for you to later consults.
Your justification also lacks development in it. Some things can be done to improve it further. For example, it is important to show evidence in the responses to support your response selection. You must also claim where's the deviation (in case there is), or analyze why there is not.

Another thing that is of extreme importance is to test your code factually (as stated before). Not only test it, but show some evidence that you did, and share the environment set for this. It's important because if the reviewer can not rut it, or if it's too complicated and time-consuming to set the correct environment, then your task is most probably going to be sent back to you. Please consider this!

Keynote for future justifications: I will show you a systematic way of building excellent-quality justifications.

Comparison between responses + Along which dimension? + Epic quality justification + Evidence for taking the aforementioned decision.
Also, you must explain and demonstrate HOW did you test the code, and how (briefly describe the environment). Extra points if you can define how to fix issues (if any).
If you follow these instructions, you will almost always be rated 4 or 5.


With all this, I truly believe you can develop perfect stellar prompts that would make the model thrive to create astonishing responses.

Thanks a lot for reading till the end! I wish you the best on this, I know you have what is needed for the project!

* Documentation:

* Flamingo Crash Course:
https://docs.google.com/document/d/1djY7NcldjU21bRYCX6hoFHrrQSPQ5C_o0d_XDJnNUmY/edit#heading=h.3ibr2go7c4fs

* Dimension Priorities:
https://docs.google.com/document/d/1XtlJbL3WuvMBqKvqSmRHVCujy_fvDrluiKOzR5I0qO4/edit